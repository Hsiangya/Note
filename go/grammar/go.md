# 数据结构

## 空结构体

`unsafe.Sizeof()`会打印int类型的长度

- int：大小跟随系统字长
- 指针的大小也是系统字长

![image-20240527102306577](./assets/image-20240527102306577.png)

- 空结构体的地址均相同（不被包含在其他结构体中时）

- 空结构体主要为了节约内存

  ```go
  // 实现一个集合
  m:=map[string]struct{}{}
  m["xx"]=struct{}{}
  
  // 管道新建,如果只想给chan发送信号 不需要值
  make(chan struct{})
  ```

## 字符串

![image-20240521223839972](./assets/image-20240521223839972.png)

- 所有字符均使用Unicode字符集

- 使用UTF-8编码

  > - 统一字符集
  > - 囊括159种文字的144679个字符
  > - 14完个字符至少需要3和字节表示
  > - 英文字符均排在前128个

- Unicode的一种变长格式

- 128个US-ASCII字符只需要一个字节编码

- 西方常用字符需要两个字节编码

- 其他字符需要三个字节，极少需要4个字节

![image-20240521224055652](./assets/image-20240521224055652.png)

**字符串的遍历**

![image-20240521225403675](./assets/image-20240521225403675.png)

## 切片

### 描述

字符串与切片都是对底层数组的引用

![image-20240521231100197](./assets/image-20240521231100197.png)

### 切片的创建

![image-20240522215357560](./assets/image-20240522215357560.png)

### 切片的访问

- 下标直接访问元素
- range遍历元素
- len(slice)查看切片长度
- cap(slice)查看数组容量

### 切片扩容

![image-20240522220648663](./assets/image-20240522220648663.png)

在分配内存空间之前需要先确定新的切片容量，运行时根据切片的当前容量选择不同的策略进行扩容：

- 如果期望容量大于当前容量的两倍就会使用期望容量
- 如果当前切片的长度小于256就会将容量返回
- 如果当前切片的长度大于256就会每次增加25%的容量，知道新容量大于期望容量

**注意**：

- 切片扩容时，**并发不安全**，注意切片并发要加锁

> 当一个线程读切片，一个线程追加扩容时，会出现读线程读取原来的数组，追加会产生新的数组，因此不安全

![image-20240522222225273](./assets/image-20240522222225273.png)

## 映射Map

映射底层使用HashMap

### 开放寻址法

![image-20240522222742034](./assets/image-20240522222742034.png)

### 拉链法

![image-20240522223145356](./assets/image-20240522223145356.png)

### go中的HashMap

![image-20240523225023502](./assets/image-20240523225023502.png)

### map初始化

**通过make初始化**：

![image-20240527105214742](./assets/image-20240527105214742.png)

**通过字面量初始化**：

![image-20240527111616172](./assets/image-20240527111616172.png)

### map的读写

**读取**：

![image-20240527111701099](./assets/image-20240527111701099.png)

**写入**：

![image-20240527112048119](./assets/image-20240527112048119.png)

### map的扩容

![image-20240527114412272](./assets/image-20240527114412272.png)

- map溢出桶太多时会导致严重的性能下降
- runtime.mapassign()可能会触发扩容情况：
  - 装在因子超过6.5（平均每个槽6.5个key）
  - 使用了太多的溢出桶（溢出桶超过了普通桶）

**扩容类型**

- 等量扩容：数据补多但是溢出桶太多了（整理）
- 翻倍扩容：数据太多了

**扩容步骤**：

- 创建新得桶
  1. 创建一组新桶
  2. oldbuckets指向原有的桶数组
  3. buckets指向新的桶数组
  4. map标记为扩容状态
- 数据迁移
  1. 将所有数据从旧桶驱逐到新桶
  2. 采用渐进式驱逐
  3. 每次操作一个旧桶时，将旧桶数据驱逐到新桶
  4. 读取时不进行驱逐，只判断读取新桶还是旧桶
- 旧buckets回收
  1. 所有的旧桶驱逐完成后
  2. oldbuckets回收

![image-20240527153453445](./assets/image-20240527153453445.png)

### map的并发

- map的读写有并发问题
- A协程在桶中读数据时，B线程驱逐了这个桶(写操作)
- A协程会读到错误的数据或者找不到数据

![image-20240527154552172](./assets/image-20240527154552172.png)

**sync.Map**:

![image-20240527155856254](./assets/image-20240527155856254.png)

**读写**：

![image-20240527162701687](./assets/image-20240527162701687.png)

### 总结

分离了扩容问题、而不是分里了写问题

- map在扩容时会有并发问题
- sync.Map 使用了两个map(read dirty)，分离了扩容问题
- 不会引发扩容的操作（查、改）使用read map
- 可能引发扩容的操作（新增）使用dirty map

> 读多追加少，使用sync.map可以大大提升效率
>
> 如果读少，追加多，和原生map加锁性能并没有提升多少

## 接口

- 只要实现了接口的全部方法，就是自动实现接口
- 可以在不修改代码的情况下抽象出新的接口

## 内存对齐

- 非内存对齐：内存的原子性与效率收到影响
- 内存对齐：提高内存操作效率，有利于原子性

![image-20240527172139096](./assets/image-20240527172139096.png)

### 基本类型对齐

**对齐系数：**

- 为了方便内存对齐，Go提供了对齐系数：`unsafe.Alignof()`
- 含义：变量的内存地址必须被对齐系数整除
- 如果对齐系数为4，表示变量内存地址必须时4的倍数

| 数据类型 | 对齐系数 |
| -------- | -------- |
| bool     | 1        |
| byte     | 1        |
| int8     | 1        |
| int16    | 2        |
| int32    | 4        |
| int64    | 8        |

> 基础类型长度大小和对齐系数一样

![image-20240527173008845](./assets/image-20240527173008845.png)

### 结构体对齐

- 结构体对齐分为内部对齐和结构体之间对齐
- 内部对齐：考虑成员大小和成员的对齐系数
- 结构体长度填充：考虑自身对齐系数和系统字长

**结构体内部对齐：**

- 指的时结构体内部成员的相对位置（偏移量）
- 每个成员的偏移量是自身大小与其对齐系数较小值的倍数

![image-20240527174812265](./assets/image-20240527174812265.png)

**结构体长度填充：**

- 指的是结构体通过增加长度，对其系统字长
- 结构体长度是最大成员长度与系统字长较小的整数倍

![image-20240527180044701](./assets/image-20240527180044701.png)

## 数据结构总结

数据结构长度：

- go中部分数据的长度与系统字长有关
- 空结构体不占用空间（独立时地址是zerobase）
- 空结构体与map结合实现hashset
- 空结构体与channel结合可以当作纯信号

内存对齐

- 提高内存效率，变量之间需要内存对齐
- 基本类型考虑对齐系数
- 结构体既需要内部对其，有需要外部填充对齐
- 空结构体作为最后一个成员，需要填充对齐

字符串与切片：

- 字符串和切片都是对底层数组的引用
- 字符串有UTF-8边长编码的特点
- 切片的容量和长度不同
- 切片追加时可能需要重建底层数组（并发不安全）

map：

- go语言使用拉链实现了hashmap
- 每一个桶中存储键哈希的前8位
- 桶超出8个数据，就会存储到溢出桶中
- 装载系数或者溢出桶的增加，会触发map扩容
- "扩容"可能并不是增加桶数，而是挣莉
- map扩容采用渐进式，桶被操作时才会从新被分配

sync.Map:

- map在扩容时会有并发问题
- sync.Map使用了两个map,分里了扩容问题
- 不会引发扩容的操作（查、改）使用read map
- 可能引发扩容的操作（新增）使用dirty map

接口：

- Go的隐式接口更加方便系统的扩产和重构
- 结构体和指针都可以实现接口
- 空结构值可以承载任何类型的数据

nil/空结构体/空接口

- nil是多个类型的零值，或者空值
- 空结构体的指针和值都不是nil
- 空接口零值是nil,一旦有了类型信息就不是nil

# Goroutine

## 进程、线程、协程

进程：

-  操作系统"程序"的最小单位
- 进程用来占用内存空间

线程:

- 每个进程可以有多个线程
- 线程使用系统分配给进程的内存，线程之间共享内存
- 线程用来占用CPU时间
- 线程的调度需要由系统进行，开销比较大
- 线程切换开销大

协程：

- 将一段程序的运行状态打包，可以在线程之间调度
- 协程并不取代线程，协程也要在线程上运行
- 线程是协程的资源，协程使用线程这个资源

## Goroutine结构

![image-20240528091249874](./assets/image-20240528091249874.png)

- runtime中，协程本质是一个g结构体
- stack：堆栈地址
- gobuf：目前程序运行现场
- atomicstatus：协程状态

![image-20240528092201169](./assets/image-20240528092201169.png)

## goroutine运行

### 单线程循环

![image-20240528104213991](./assets/image-20240528104213991.png)

- 协程的本质是一个g结构体
- g结构体记录了协程栈、PC信息
- 嘴贱情况下，线程执行标准调度循环，执行协程

### 多线程循环

![image-20240528104509371](./assets/image-20240528104509371.png)

- 操作系统并不知道goroutine的存在
- 操作系统线程执行一个调度循环，顺序执行Goroutine
- 调度循环非常像线程池

## GMP调度模型

### 结构

解决的问题：

- 协程顺序执行，无法并发
- 多线程并发时，会抢夺协程队列的全局锁

![image-20240528110300168](./assets/image-20240528110300168.png)

### gouroutine的获取

**P的作用**

- M与G之间的中介（送料器）
- P持有一些G，使得每次获取G的时候不用从全局找
- 大大减少了并发的执行

![image-20240528115732012](./assets/image-20240528115732012.png)

- 先从本地队列获取goroutine
- 本地没有则上锁，从全局队列获取
- 如果全局队列也没用，去其他的P偷取
- 增加了goroutine的利用路

### goroutine的新建

- 随机寻找一个P
- 将新协程放入P的runnext（插队）
- 若P本地队列满了，放入全局队列

![image-20240528120512499](./assets/image-20240528120512499.png)

解决了问题：

- 多线程并发时，会抢夺协程队列的全局锁

### goroutine的并发

![image-20240528121756083](./assets/image-20240528121756083.png)

### goroutine的切换

#### 主动挂起

![image-20240528122903281](./assets/image-20240528122903281.png)

#### 系统完成调用时

![image-20240528123723701](./assets/image-20240528123723701.png)

#### 总结

- 协程顺序执行，会有饥饿问题
- 协程执行中间，将协程挂起，执行其他协程
- 完成系统调用时挂起，也可以主动挂起
- 方只全局队列饥饿，本地队列随机抽取全局队列

## groutine调度

### 基于协作的抢占式调度

![image-20240528172526264](./assets/image-20240528172526264.png)

### 基于信号的抢占式调度

如果一个goroutine永远不调用morestack()，此时依靠基于信号的抢占式调度

- 操作系统中，有很多基于信号的底层通信方式
- 比如SIGPIPE/SIGURG/SIGHIP
- 线程可以注册对应信号的处理函数

流程：

- 注册SIGURG信号的处理函数（紧急信号）
- GC工作时，向目标线程发送信号
- 线程收到信号，触发调度

![image-20240528173248921](./assets/image-20240528173248921.png)

### 总结

- 基于系统调用和主动挂起，协程可能无法调度
- 基于**协作**的抢占式调度：业务主动调用morestack()
- 基于**信号**的抢占式调度：强制线程调用doSigPreempt()

## 协程太多的问题

**限制goroutine的原因**：

- 文件打开数限制
- 内存限制
- 调度开销过大

**解决方法**：

- 优化业务逻辑

- 利用channel的缓冲区

  ![image-20240528174210490](./assets/image-20240528174210490.png)

  > 适合一大批相同情况下的goroutine

- 协程池

  > 预创建一些协程，使用的时候从池子里拿出一些，使用完后放回
  >
  > go的GMP模型已经类似于池化过了，go的初中时希望goroutine即用即毁

- 调整系统资源

**总结**:

- 太多的goroutine会给程序运行带来性能和稳定性问题
- 牺牲并发特性，利用channel缓冲

## 总结

为什么用协程：

- 协程用来精细利用线程
- 协程可以支撑超高并发

协程是什么：

- 从runtime的角度看，协程就是一个可以被调度的g结构体
- 从线程的角度看，协程就是一段程序，自带执行现场

GMP模型：

- 通过P结构体，达成了缓存部分G的目的
- P本质上就是一个G的本地队列，避免全局并发等待
- 窃取式工作分配机制能够更加充分利用线程资源

协程并发：

- 如果协程顺序执行，会有饥饿问题
- 协程执行中间，将携程挂起，执行其他协程
- 完成系统调用时挂起，也可以主动挂起
- 防止全局队列饥饿，本地队列随机抽取全局队列

抢占式调度：

- 基于系统调用和主动挂起，协程可能无法调度
- 基于写作的抢占式调度：业务主动调用morestack()
- 基于信号的抢占式调度：强制线程调用doSigPreempt()

# 锁

## atomic

![image-20240528202430290](./assets/image-20240528202430290.png)

- 原子操作时一种硬件层面加锁的机制
- 保证操作一个变量的时候，其他协程/线程无法访问
- 只能用于简单变量的简单操作（无法锁结构体及复杂变量）

![image-20240528203817735](./assets/image-20240528203817735.png)

## sema 锁

### sema锁结构

- 也叫信号量锁/信号锁
- 核心时一个unit32值，含义是同时可以并发的数量
- 每一个sema锁都对应一个SemaRoot结构体
- 每一个semaRoot中有一个平衡二叉树用于协程排队

![image-20240528210447703](./assets/image-20240528210447703.png)

### sema操作

uint32>0时：

- 获取锁：uint32减1，获取成功
- 释放锁：uint32加1，释放成功

![image-20240528212324609](./assets/image-20240528212324609.png)

uint32==0时：

- 获取锁：goroutine休眠，进入堆树等待
- 释放锁：从堆树中取出一个goroutine,唤醒
- sema锁退化成一个专用休眠队列

![image-20240528214109943](./assets/image-20240528214109943.png)

### 总结

- 原子操作时一种硬件层面加锁的机制
- 数据类型和操作类型有限制
- sema锁是runtime的常用工具
- sema经常被用作休眠队列

## Mutex

- go的互斥锁
- go中用于并发保护最常见方案

### 结构

![image-20240529083657279](./assets/image-20240529083657279.png)

### 正常模式

#### 加锁

- 尝试CAS直接加锁
- 若无法直接获取，进行多次自旋尝试
- 多次尝试失败，进入sema队列休眠

![image-20240529091455300](./assets/image-20240529091455300.png)

#### 解锁

- 尝试CAS直接解锁
- 若发现有协程在sema中休眠，唤醒一个协程

![image-20240529093613963](./assets/image-20240529093613963.png)

#### 总结

- mutex正常模式：自旋加锁+sema休眠等待
- mutex正常模式下：可能有锁饥饿问题（休眠唤醒的锁任然获取不到锁，进入休眠状态）

### 饥饿模式

- 当前goroutine等待锁的时间超过了1ms，切换到饥饿模式
- 饥饿模式中，不自旋，新来的goroutine直接sema休眠
- 饥饿模式中，被唤醒的gorouine直接获取锁
- 没有goroutine在队列中继续等待时，回到正常模式

![image-20240529103733781](./assets/image-20240529103733781.png)

- 锁 竞争严重时，互斥锁进入饥饿模式
- 饥饿模式没有自旋等待，有利于公平

### 使用经验

- 减少锁的使用时间

  > 不会产生并发问题的代码不进行上锁，只加锁会产生并发竞争的部分

- 善用defer，确保锁的释放

  > 如果在加锁中间，程序中断，导致关闭锁异常，会影响后续程序逻辑处理

## RWMutex

### 结构

- 只读时，让其他人不能修改即可
- 只读时，多协程可以共享读
- 只读时，不需要互斥锁

![image-20240529175721853](./assets/image-20240529175721853.png)

读写锁需求：

- 每个锁分为读锁和写锁，写锁互斥
- 没有加写锁时，多个协程都可以加读锁
- 加了写锁时，无法加读锁，读协程排队等待
- 加了读锁，写锁排队等待

![image-20240529181158420](./assets/image-20240529181158420.png)

### 写锁

- 先加mutex写锁，若已经被加写锁会阻塞等待
- 将readerCount变为负值，阻塞读锁的获取
- 计算需要等待多少个读goroutine释放
- 如果需要等待读goroutine释放，陷入writeSem

#### 加锁

![image-20240529183158786](./assets/image-20240529183158786.png)![image-20240529184208270](./assets/image-20240529184208270.png)

#### 解锁

- 将readerCount变为正值，允许读锁的获取
- 释放readerSem中等待的读goroutine
- 解锁mutex

![image-20240529184952307](./assets/image-20240529184952307.png)

### 读锁

#### 加锁

- 将readerCount无脑加一
- 如果readerCounter是正数，加锁成功
- 如果readerCount是负数，说明被加了写锁，陷入readerSem

![image-20240529185958796](./assets/image-20240529185958796.png)

#### 解锁

- 给readerCount减1
- 如果readerCount是正数，解锁成功
- 如果readerCount是负数，有写锁在排队
  - 如果自己是readerWait的最后一个，唤醒写goroutine

![image-20240529191031919](./assets/image-20240529191031919.png)

### 总结

场景：

- RW锁适合读多写少的场景，减少锁冲突
- Mutex用来写goroutine之间互斥等待
- 读goroutine使用readerSem等待写锁的释放
- 写goroutine使用writerSem等待锁的释放
- readerCount记录读goroutine个数
- readerWait记录写goroutine之前的读goroutine个数

## WaitGroup

### wait

![image-20240529200853490](./assets/image-20240529200853490.png)

### done

- 被等待协程做完，给counter减1
- 通过Add(-1)实现

![image-20240529201637531](./assets/image-20240529201637531.png)

### 总结

- WaitGroup实现了一组goroutine等待另一组goroutine
- 等待的goroutine陷入sema并记录个数
- 被等待的goroutine计数归零时，唤醒所有sema中的goroutine

## once

整个程序运行过程中，代码只执行一次

思路1：找一个变量记录一下，从0变成1就不再做了

- 做法：CAS改值，成功就做
- 方法简单，多个goroutine竞争CAS改值会造成性能问题

思路2：Mutex

- 争抢一个mutex,抢不到陷入sema休眠
- 抢到的执行代码，改值，释放锁
- 其他goroutine唤醒后判断值已经修改，直接返回

![image-20240529203323312](./assets/image-20240529203323312.png)

执行方式：

- 先判断是否已经改值
- 没改，尝试获取锁
- 获取到锁的goroutine执行业务，修改值，解锁
- 冲突goroutine唤醒后直接返回

**总结**：

- 实现了一段代码只执行一次
- 使用标志加mutex实现了并发冲突的优化

## 锁异常排查

### 锁拷贝问题

- 锁拷贝可能导致锁的死锁问题

  ![image-20240529204215707](./assets/image-20240529204215707.png)

- 使用go vet main.go 可以检查是否有锁拷贝的情况

- vet还能检测可能的bug或者可疑的构造

### RACE竞争检测

源码中到处都有race竞争检测

```go
if race.Enabled {
    race.Acquire(unsafe.Pointer(m))
}
return
```

- 发现隐形函数竞争问题
- 使用go build -race main.go 然后运行，如果存在锁竞争，运行编译后的文件的时候会报错
- 可能是加锁的建议
- 可能是BUG的提醒

### go-deadlock检测

死锁检测：`https://github.com/sasha-s/go-deadlock`

- 检测可能的死锁
- 实际是检测获取锁的等待时间
- 用来排查bug和性能问题

### 总结

- go ver 检测bug或者可以的构造
- race 发现隐含的数据竞争问题
- go-deadlock检测可能的死锁

# Channel

## 描述

- 不要通过共享内存的方式进行通信
- 而是应该通过通信的方式共享内存

![image-20240529214531229](./assets/image-20240529214531229.png)

为什么使用通信来共享内存：

- 避免goroutine竞争和数据冲突的问题
- 更高级的抽象，降低开发难度，增加程序可读性
- 模块之间更容易解耦，增加扩展性和可维护性

## 数据结构

![image-20240529221548487](./assets/image-20240529221548487.png)

## 发送数据

- c <- 关键字是一个语法糖
- 编译阶段，会把c <- 转化为runtime.()
- chansend1()会调用chansend()方法

### 直接发送

数据发送前，已经有G再休眠等待接收

- 从队列里取出一个等待接收的G
- 将数据直接拷贝到接收变量中
- 唤醒G

![image-20240530095334549](./assets/image-20240530095334549.png)

### 放入缓存

- 获取可存入地缓存地址
- 放入数据
- 维护索引

![image-20240530101138189](./assets/image-20240530101138189.png)

### 休眠等待

- 把自己包装成sudog
- sudog放入sendq队列
- 休眠并解锁
- 被唤醒后，数据已经被取走，维护其他数据

![image-20240530102027562](./assets/image-20240530102027562.png)

### 总结

编译阶段，会把`<-` 转化为runtime.chansend1() 

1. 直接发送时，将数据直接拷贝到目标变量
2. 放入缓存时，将数据放入环形缓存，成功返回
3. 休眠等待时，将自己包装成sudog后放入sendq，休眠

## 数据接收

`< -c`关键字，是一个语法糖

- 编译阶段，`i <-c`转化为runtime.chanrecv1()
- 编译阶段，`i,ok < - c`转化为runtime.chanrecv2()
- 最后会调用chanrecv()方法

![image-20240530102916941](./assets/image-20240530102916941.png)

### sendq等待，直接接收

- 判断有G在发送队列等待，进入recv()
- 判断此Channel无缓存
- 直接从等待的G中取走数据，唤醒G

![image-20240530104701114](./assets/image-20240530104701114.png)

### sendq等待，接收缓存

- 判断G在发送队列等待，进入recv()
- 判断此Channel有缓存
- 从缓存中取走一个数
- 将G的数据放入缓存，唤醒G

![image-20240530111631342](./assets/image-20240530111631342.png)

### 接收缓存

- 判断没有G在发送队列等待
- 判断此Channel有缓存
- 从缓存中取走一个数据

![image-20240530122134877](./assets/image-20240530122134877.png)

### 阻塞接收

- 判断没有G在发送队列等待
- 判断此Channel无缓存
- 将自己包装成sudog
- sudog放入接收等待队列，休眠
- 唤醒时，发送的G已经把数据拷贝到位

![image-20240530123037541](./assets/image-20240530123037541.png)

### 总结

- 编译阶段，`<-c`会转化为chanrecv()
- 有等待G，且无缓存时，从G接收
- 有等待G，且有缓存时，从缓存接收
- 无等待的G，且缓存有数据，从缓存接收
- 无等待的G，且缓存无数据，等待喂数据

## 非阻塞的Channel

select：

- 同时存在接收、发送、默认路径
- 首先查看是否有即时执行的case
- 没有的话，有default,走default

![image-20240530132755949](./assets/image-20240530132755949.png)

timer：

- timer可以提供一个channel，定时塞入数据

![image-20240530133102351](./assets/image-20240530133102351.png)

## 总结

为什么使用channel:

- 相对于无锁：
  - 避免goroutine竞争和数据冲突的问题
- 相对于加锁：
  - 更高级的抽象，降低开发难度，增加程序可读性
  - 模块之间更容易解耦，增强扩展性和可维护性

**channel基本结构：**

- 一个环形缓存
- 两个链表（发送goroutine/接收goroutine）
- 一个互斥锁（保护hchan）
- 一个状态值

**数据发送原理：**

- 直接发送时，将数据直接拷贝道目标变量
- 放入缓存时，将数据放入环形缓存，成功返回
- 休眠等待时，将自己包装后放入send，休眠

**数据接收原理：**

- 有等待的G，且无缓存时，从G接收
- 有等待的G，且有缓存时，从缓存接收
- 五等待的G，且缓存有数据，从缓存接收
- 无等待的G，且缓存无数据，等待喂数据

**非阻塞channel**:

- 使用select可以使用channel的非阻塞特性
- 使用timer配合select可以实现超时特性

# 网络编程

## 介绍

![image-20240530214150168](./assets/image-20240530214150168.png)

三次握手：

1. SYN：客户端发送一个SYN（同步序列编号）数据包到服务器以初始化一个连接，在这个数据包中，客户端将它的处时序列号（ISN）设置为一个随机值
2. SYNC-ACK：服务器接收到SYN，回送一个确人数据包（ACK）给客户端。这个数据包包括：
   - ACK的序号为客户端的ISN加1（A+1），表示服务器已经接收客户端的SYN
   - 服务器自己的SYN数据包，包含服务器的吃书序列号B
3. ACK：客户端接收服务器的SYN-ACK后，发送一个确认包（ACK）回到服务器。这个ACK的序号被设置为服务器的ISN加1（B+1）

四次挥手：

1. FIN：客户端决定数据发送完成后，它发送一个FIN数据包给服务器，表示它没有数据发送了，并想关闭连接

2. ACK：服务器接收到这个FIN后，发送一个ACK给客户端，确人收到了客户端的终止请求

3. FIN：服务器完成他的数据发送后，发送一个FIN给客户端，告知客户端它也没有数据要发送了

4. AKC：客户端接收到服务器的FIN后，发送一个ACK给服务器。这之后，客户端进入TIME-WAIT状态

   > TIME-WAIT状态持续一段时间（通常是2个最大段生命周期（MSL）），确保服务器接收到最终的ACK。一旦这个时间过去，连接被完全关闭，并且双方都释放了所有资源。

## scoket

### 通信过程

- 很多系统都提供Socket作为TCP网络连接的抽象

- Linux --> INternet domain socket -> SOCK_STREAM

  > 每次有一个三次握手，就有一个socket，不需要再关心底层

- Linux 中socket以“文件描述符"FD作为标识

![image-20240531011955230](./assets/image-20240531011955230.png)

### Server实现

#### server单连接

![im![image-20240926151853195](./assets/image-20240926151853195.png)

#### server多连接

![image-20240926163413682](./assets/image-20240926163413682.png)

### Client实现

![image-20240926153305004](./assets/image-20240926153305004.png)

### listen源码

- 新建一个socket，并执行bind操作
- 新建一个FD（net包对socket的详情描述）
- 返回一个TCPListener对象
- 将TCPListener的FD信息加入监听
- TCPListener对象本质上是一个LISTEN状态的socket
- 从通信过程来看，走到了第一步

![image-20240531152737700](./assets/image-20240531152737700.png)

![image-20240531151125715](./assets/image-20240531151125715.png)

### Accept源码

- 直接调用socket的accept
- 试过失败，休眠等待新的连接
- 将新的socket包装为tcpConn变量返回
- 将TCP Conn的FD信息加入监听
- TCPConn本质上是一个ESTABLISHED状态的Socket
- 从通信过程来看，走到了第二步

![image-20240531152708170](./assets/image-20240531152708170.png)

![image-20240531153602085](./assets/image-20240531153602085.png)



![image-20240531153358275](./assets/image-20240531153419092.png)![image-20240531153440792](./assets/image-20240531153440792.png)

![image-20240531153514337](./assets/image-20240531153514337.png)

## IO模型

IO模型指的是同时操作Socket的方案

### 阻塞IO

- 同步读写Socket时，线程陷入内核态
- 当读写成功后，切换回用户态，继续执行
- 优点：开发难度小，代码简单
- 缺点：内核态切换开销大

![image-20240531012626949](./assets/image-20240531012626949.png)

### 非阻塞IO

- 如果暂时无法收发数据，会返回错误
- 应用会不断轮寻，知道socket可以读写
- 优点：不会陷入内核态，自由度高
- 缺点：需要自旋轮寻

![image-20240531012840494](./assets/image-20240531012840494.png)

### 多路复用-epoll

- 注册多个Socket事件
- 调用epoll，当有事件发生，返回
- 有点：提供了事件列表，不需要查询各个socket
- 缺点：开发难度大，逻辑复杂
- mac：kqueue; windows：IOCP

![image-20240531013707576](./assets/image-20240531013707576.png)

### 总结

- 操作系统提供了socket作为tcp通信的抽象
- IO模型指的是操作Socket的方案
- 阻塞模型最利于业务编写，但是性能最差
- 多路复用性能好，但业务编写麻烦

## 阻塞模型+多路复用

### 原理

![image-20240531014439622](./assets/image-20240531014439622.png)

![image-20240531014624100](./assets/image-20240531014624100.png)

- 在底层使用操作系统的多路复用IO
- 在goroutine层次使用阻塞模型
- 阻塞goroutine时，休眠goroutine

由于go是跨平台的，所以一定有一个抽象层，统一操作系统的多路复用：

- 新建多路复用器：epoll_create()
- 往多路复用器里插入需要监听的事件：epoll_ctl()
- 查询发生了什么事件：epoll_wait()

![image-20240531023504085](./assets/image-20240531023504085.png)

go Network Poller多路复用器的抽象：

- Go Network Poller 对于多路复用器的抽象和适配
- epoll_create() --> netpollinit()
- epoll_ctl() --> netpollopen()
- epoll_wait() --> netpoll()

不用再关心底层操作系统以及使用的是什么形式的多路复用，直接调用对应方法

### netepollinit

- 新建Epoll
- 新建一个pipe管道用于中断Epoll
- 将“管道有数据到达“事件注册在Epoll中

![image-20240531024451184](./assets/image-20240531024451184.png)

### netpollopen

- 传入一个Socket的FD和pollDesc指针
- pollDesc指针是Socket相关详细信息
- pollDesc中记录了哪个goroutine休眠在等待此Socket
- 将Socket可读、可写、断开事件注册到Epoll中



![image-20240531025458386](./assets/image-20240531025458386.png)

### netpoll

- 调用epoll_wait()，查询有哪些事件发生
- 根据socket相关的pollDesc信息，返回哪些goroutine可以唤醒

![image-20240531031846730](./assets/image-20240531031846730.png)![image-20240531031907681](./assets/image-20240531031907681.png)![image-20240531031950575](./assets/image-20240531031950575.png)![image-20240531032017422](./assets/image-20240531032017422.png)

### 总结

- go将多路复用器的操作进行了抽象和适配;
  - 将新建多路复用器抽象为了netpollinit()
  - 将插入监听事件抽象为了netpollopen()
  - 将查询事件抽象为了netpoll
  - 但不是返回事件，而是返回等待事件的goroutine列表

## Network Poller

### 初始化

- poll_runtime_pollServerInit()
- 使用原子操作保证只初始化一次
- 调用netpollinit()

![image-20240531120141618](./assets/image-20240531120141618.png)



### 工作(pollcache和pollDesc)

- pollcache：一个带锁的链表头

- pollDesc：链表成员

- pollDesc是runtime包对socket详细的描述

- rg，wg：1,或2,或等待的gouroutine的地址

  ![image-20240531121333243](./assets/image-20240531121333243.png)

![image-20240531121150721](./assets/image-20240531121150721.png)

### 新增监听Socket(pollOPen)

![image-20240531122900745](./assets/image-20240531122900745.png)![image-20240531122942921](./assets/image-20240531122942921.png)

- poll_runtime_pollOpen()
- 在pollcache链表中分配一个pollDesc
- 初始化pollDesc（rg，wg都为0）
- 调用netpollopen()

### 收发数据

#### socket已经可读写

- runtime循环调用netpoll方法（g0 gotoutine）
- 发现socket可读或可写，给对应的rg或者wg置为pdReady(1)
- goroutine调用poll_runtime_pollWait()
- 判断rg或者wg已经置为pdReady(1)，返回0

![image-20240531140756187](./assets/image-20240531140756187.png)![image-20240531141723838](./assets/image-20240531141723838.png)

![image-20240531142358659](./assets/image-20240531142358659.png)![image-20240531142434467](./assets/image-20240531142434467.png)



#### socket暂时无法读写

- runtime循环调用netpoll()方法（g0 gouroutine）

- gouroutine调用poll_runtime_pollWait()
- 发现对应的rg或者wg置为0
- 给对应的rg或者wg置为goroutine地址
- 休眠等待
- runtime后续循环调用netpoll方法 发现可读状态，会被推送到toRun链表中
- 发现socket可读写时，给对应的查看对应的rg或者wg
- 若为goroutine地址，返回goroutine地址
- 调度器开始调度对应gotourine

![image-20240531143410799](./assets/image-20240531143410799.png)

#### 总结

![image-20240531143815798](./assets/image-20240531143815798.png)

- Network Poller是Runtime的强大工具
- 抽象了多路复用的操作
- Network Poller可以自动监测多个Socket状态
- 在Socket状态可用时，快速返回成功
- 在Socket状态不可用时，休眠等待

## 网络通信过程



# 内存管理

## 内存分配器

程序中的数据和变量都会被分配到程序所在的虚拟内存中，内存空间包含两个重要区域：栈区(Stack)和堆区(Heap)。

**栈区**：

- 函数调用的参数、返回值以及局部变量大都会被分配到栈上
- 这部分内存会由编译器进行管理
- Go 以及 Java 等编程语言会由工程师和编译器共同管理

**堆区**：

- 堆中的对象由内存分配器分配并由垃圾收集器回收

### 设计原理

![image-20240514171524393](./assets/image-20240514171524393.png)

内存分配器一般包含两种分配方法：

- 线性分配器（Sequential Allocator，Bump Allocator）
- 空闲链表分配器（Free-List Allocator）

### 线性分配器

![image-20240514173026903](./assets/image-20240514173026903.png)

由于线性分配器具有上述特性，所以需要与合适的垃圾回收算法配合使用：

- 标记压缩（Mark-Compact）
- 复制回收（Copying GC）
- 分带回收（Generational GC）
- .........

它们可以通过拷贝的方式整理存活对象的碎片，将空闲内存定期合并，这样就能利用线性分配器的效率提升内存分配器的性能

线性分配器需要与具有拷贝特性的垃圾回收算法配合，所以C与C++等需要直接对外暴露指针的语言就无法使用该策略

### 空闲链表分配器

因为不同的内存块通过指针构成了链表，所以这种方式的分配器可以重新利用回收的资源，但是因为分配内存时需要遍历链表，所以时间复杂度是O(n)，空闲链表分配器可以选择不同的策略再链表中的内存块中进行选择：

- 首次适应（First-Fit）：从链表头开始遍历，选择第一个大小大于申请内存的内存块
- 循环首次适应（Next-Fit）：从上次遍历的结束位置开始遍历，选择第一个大小大于申请内存的内存块
- 最优适应（Best-Fit）：从链表头遍历整个链表，选择最合适的内存块
- 隔离适应（Segregated-Fit）：将内存分割成多个链表，每个链表中的内存块大小相同，申请内存时先找到满足条件的链表，再从链表中选择合适的内存块

go语言使用的内存分配策略与第四种策略有些相似：

![image-20240514174704702](./assets/image-20240514174704702.png)

### 分级分配

线程缓存分配（Thread-Caching Malloc，TCMalloc）是用于分配内存的机制，Go 语言的内存分配器就借鉴了 TCMalloc 的设计实现高速的内存分配，它的核心理念是使用多级缓存将对象根据大小分类，并按照类别实施不同的分配策略。

**对象大小**

go语言的内存分配器会根据申请分配的内存大小选择不同的逻辑处理，运行时根据对象的大小将对象分成**为对象、小对象和大对象**:

| 类别   | 大小         |
| ------ | ------------ |
| 微对象 | `(0,16B)`    |
| 小对象 | `[16B,32KB]` |
| 大对象 | `(32KB,+∞)`  |

因为程序冲的绝大多数对象的大小都在32KB一下，而申请的内存大小影响Go运行时分配内存的过程和开销，所以分别处理大对象和小对象有利于提高内存分配器的性能

### 分级缓存

内存分配不仅会区别对待大小不同的对象，还会将内存分成不同的级别进行管理，TCMalloc和go运行时分配器都会引入线程缓存（Thread Cache）、中心缓存（Central Cache）和页堆（Page Heap）三个组件分级管理内存：

![image-20240514222156144](./assets/image-20240514222156144.png)

### 线性内存

go1.10以前的版本，堆区内存空间都是连续的

![image-20240515114021774](./assets/image-20240515114021774.png)

- 对于任意一个地址，可以根据据arena的基地址计算出所在的页数并通过spans数组获得管理该片区内存的管理单元runtime.mspan
- spans数组中多个连续的位置可能对应同一个runtime.mspan结构

go 语言在垃圾回收机制时会根据指针的地址判断对象是否在堆中，并通过上述方法找到管理对象runtime.mspan。这些都建立在堆区的内存是连续的这一假设上。这种设计虽然简单并且防弊案，但是在C和go混合使用时会导致程序崩溃

1. 分配的内存地址会发生冲突，导致堆的初始化和扩容失败
2. 没有被预留的大块内存可能会被分配给C语言的二进制，导致扩容后的堆不连续

线性的堆内存需要预留大块的内存空间，但是申请大块的内存空间而不适用时不切实际的，不预留内存空间却会在特殊场景下造成程序崩溃。虽然连续内存的实现比较简单，但是这些问题也没有办法忽略。

**内存申请流程**：

1. 内存申请
2. 通过bitmap查找空闲内存
3. 通过arena的基地址获取管理器spans
4. 分配内存，求改bitmap中该内存使用情况

### 稀疏内存

稀疏内存是 Go 语言在 1.11 中提出的方案，使用稀疏的内存布局不仅能移除堆大小的上限，还能解决 C 和 Go 混合使用时的地址空间冲突问题。不过因为基于稀疏内存的内存管理失去了内存的连续性这一假设，这也使内存管理变得更加复杂：

![image-20240515140848172](./assets/image-20240515140848172.png)

不同平台和架构的二维数组大小可能完全不同：

- go语言服务在Linux的x86-64架构上运行，二维数组的一维大小会是1，二位大小是4394304

  > 每一个指针占用8字节的内存空间，所以辕信息的总大小是32MB

- 由于每个runtime.heapAreana都会管理64MB的内存，整个堆区最多可以管理256TB的内存，这比之前的512GB多好几个数量级

由于内存的管理变得更加复杂，上述改动对垃圾回收稍有影响，大约会增加 1% 的垃圾回收开销，不过

## 垃圾收集器

### 设计原理

![image-20240515141523513](./assets/image-20240515141523513.png)

##

### 标记清除

标记清楚Mark-Sweep算法是最常见的垃圾收集算法，标记清楚收集器是跟踪式垃圾收集器，其执行过程可以分成标记（Mark）和清楚（Sweep）两个阶段

1. 标记阶段：从跟对象触发查找并标记堆中所有存活的对象
2. 清除阶段：遍历堆中的全部对象，回收未被标记的垃圾对象并将回收的内存加入空闲链表

![image-20240515143506131](./assets/image-20240515143506131.png)

- 垃圾收集器从垃圾手机的根对象触发，递归遍历这些对象指向的子对象并将所有可达的对象标记成存活
- 标记结束后，垃圾收集器会依次遍历堆中的对象并清楚其中的垃圾，整个过程需要标记对象的存活状态，用户程序在垃圾收集的过程中页不能执行
- 我们需要用到更复杂的机制来解决STW的问题

### 三色抽象

为了解决原始标记清楚算法带来的长时间STW，多数现代的追踪是垃圾收集器都会实现三色标记算法的变种以缩短STW的时间，三色标记算法将程序中的对象分成白色、黑色、灰色三类：

- 白色对象：潜在的垃圾，其内存可能会被垃圾收集器回收
- 黑色对象：活跃的对象，包括不存在任何引用外部指针的对象以及从跟对象可达的对象
- 灰色对象：活跃的对象，因为存在指向白色对象的外部指针，垃圾收集器会扫描这些对象的子对象

![image-20240515145803251](./assets/image-20240515145803251.png)

三色标记垃圾收集器工作原理：

- 从灰色对象的集合中选择一个灰色对象，并将其标记成黑色
- 将黑色对象指向的所有对象都标记成灰色，保证该对象和被该对象引用的对象都不会被回收
- 重复上述两个步骤知道对象图中不存在灰色对象

![image-20240515150232574](./assets/image-20240515150232574.png)

 ![image-20240515150458116](./assets/image-20240515150458116.png)

本来不应该回收的对象却被回收了，这在内存管理中是非常严重的错误，将这种错误成为悬挂指针

### 屏障技术

- 多数的现代处理器都会乱序执行指令以最大化性能
- 该技术能够保证内存操作的顺序性，在内存屏障前执行的操作一定会先于内存品璋后执行的操作一定会先于内存屏障后执行的操作 

想要在并发或者增量的标记算法中保证正确性，需要达成一下两种三色不变性（Tri-color invariant）中的一种：

- 强三色不变性：黑色对象不会指向白色对象，只会指向灰色对象或者黑色对象
- 弱三色不变性：黑色对象指向的白色对象必须包含一条从灰色对象经由多个白色对象的可达路径

![image-20240515155416688](./assets/image-20240515155416688.png)

垃圾收集中的屏障技术更像是一个钩子方法，他是在用户程序读取对象、创建对象以及更新对象指针时执行的一段代码，根据操作类型的不同，我们可以分成读屏障（Read barrier）和写屏障（Write barrier）:

- 读屏障需要在读操作中加入代码片段，对用户程序的性能影响很大，所以变成语言往往都会采用写屏障保证三色不变性

### 插入写屏障

![image-20240515161620591](./assets/image-20240515161620591.png)

### 删除写屏障

删除写屏障一旦开始工作，他会保证开启写屏障时堆上搜友对象的可达，所以也被称作快照垃圾收集（Snapshot GC）

![image-20240519192055935](./assets/image-20240519192055935.png)

### 三色标记法+混合写屏障机制

- 插入写屏障不足：结束时需要STW来重新扫描栈，大约需要10~100ms
- 删除写屏障不足：回收精度低，一个对象即使被删除了最后一个指向它的指针也依旧可以活过这一轮，在下一轮GC中被清理掉

GoV1.8的三色标记法+混合写屏障机制：

1. GC开始将栈上的对象全部扫描并标记为黑色（之后不在进行第二次重复扫描，无需STW）
2. GC期间，任何在栈上创建的新对象，均为黑色
3. 被删除的对象标记为灰色
4. 被添加的对象标记为灰色

**满足变形的弱三色不变式（结合了插入、删除写屏蔽两者的优点）**

![image-20240519214201428](./assets/image-20240519214201428.png)

### 混合写屏障案例场景

#### 堆对象删除，栈对象引用

![image-20240519215940169](./assets/image-20240519215940169.png)

#### 栈对象删除，栈对象引用

![image-20240519223845452](./assets/image-20240519223845452.png)

#### 堆对象删除，堆对象引用![image-20240519224538682](./assets/image-20240519224538682.png)

#### 栈对象删除，堆对象引用

![image-20240519225424875](./assets/image-20240519225424875.png)

### GC总结

- 强三色不变式：强制性的不允许黑色对象引用白色
- 弱三色不变式：黑色对象可以引用白色对象，但该白色对象必须存在灰色对象引用它
- 三色标记满足强弱不变式之一，即可保证对象不丢失
- 为了满足强三色：插入屏障：添加一个下游引用对象时，标记为灰色
- 为了满足弱三色：删除屏障，当一个对象被删除时，标记为灰色

为了不进行STW，引入了三色标记和混合写屏障

- 栈中能到达的对象都标记为灰色
- 堆中的对象启用插入写屏障和删除写屏障
- 这总情况被删除的对象不被其他对象引用，会在当前的GC周期存活，下一个GC周期被回收
